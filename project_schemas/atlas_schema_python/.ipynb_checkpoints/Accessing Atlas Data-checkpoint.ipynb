{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to DataJoint server\n",
    "#### Downloading data from S3 will require your own AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataJoint connection (connected) alex@ucsd-demo-db.datajoint.io:3306"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "import json\n",
    "from utilities import *\n",
    "from subprocess import call\n",
    "\n",
    "# Connect to datajoint server\n",
    "dj.conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which schema you're using\n",
    "schema = dj.schema('common_atlas')\n",
    "schema.spawn_missing_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dictionary of brain names from utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MD585', 'MD589', 'MD590', 'MD591', 'MD592', 'MD593', 'MD594', 'MD595', 'MD598', 'MD599', 'MD602', 'MD603', 'CHATM2', 'CHATM3', 'CSHL2', 'MD658', 'MD661', 'MD662', 'MD635', 'MD636', 'MD639', 'MD642', 'MD652', 'MD653', 'MD657', 'MD175', 'UCSD001']\n"
     ]
    }
   ],
   "source": [
    "# From utilities.py\n",
    "all_stacks = list( brain_names_dic.keys() )\n",
    "print( all_stacks )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all Section-names & Section-numbers for a given stack\n",
    "#### - Example displaying MD585 sections\n",
    "`Placeholder` indicates a damaged section, not used in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys for <STACK>_stack_info:\n",
      "odict_keys(['mouse', 'stack_name', 'num_slices', 'num_valid_slices', 'channels', 'sorted_filenames', 'human_annotated', 'planar_resolution_um', 'section_thickness_um'])\n"
     ]
    }
   ],
   "source": [
    "stack = 'MD585'\n",
    "MD585_stack_info = (BrainStackInfo()&dict(mouse=stack)).fetch( as_dict=True )[0]\n",
    "print( 'Keys for <STACK>_stack_info:')\n",
    "print( MD585_stack_info.keys() )\n",
    "\n",
    "# `MD585_sections` contains a list of every filename, <space>, and the section number\n",
    "#    If filename == 'Placeholder' then the section is unusable and not used in the pipeline\n",
    "MD585_sections = MD585_stack_info['sorted_filenames'].split('|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Raw Data\n",
    "#### - Example accessing MD585 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHATM2\n",
      "  - Has no raw data on S3\n",
      "CHATM3\n",
      "  - Has no raw data on S3\n",
      "CSHL2\n",
      "  - Has no raw data on S3\n",
      "MD639\n",
      "  - Has no raw data on S3\n",
      "MD175\n",
      "  - Has no raw data on S3\n"
     ]
    }
   ],
   "source": [
    "# Going through each brain, prints out brains that do NOT have raw data\n",
    "for stack in all_stacks:\n",
    "    # rawstack_info keys: ['mouse', 'aws_bucket', 'processed_stack']\n",
    "    raw_stack_info = (RawStack()&dict(mouse=stack)).fetch( as_dict=True )[0]\n",
    "    if raw_stack_info['raw_stack']=='':\n",
    "        print(raw_stack_info['mouse'])\n",
    "        print( '  - Has no raw data on S3' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 100th slice of MD585 with the bucket appended to the front:\n",
      "\n",
      "mousebrainatlas-rawdata://CSHL_data/MD585/MD585-IHC42-2015.08.19-14.26.30_MD585_1_0124_lossless.jp2\n"
     ]
    }
   ],
   "source": [
    "stack = 'MD585'\n",
    "# Load RawStack table (as dict) for a particular stack\n",
    "raw_stack_info = (RawStack()&dict(mouse=stack)).fetch( as_dict=True )[0]\n",
    "\n",
    "bucket =  raw_stack_info['aws_bucket']\n",
    "filename_list = raw_stack_info['raw_stack'].split('|')\n",
    "\n",
    "print( 'The 100th slice of '+stack+' with the bucket appended to the front:\\n' )\n",
    "fp = bucket + '://' + filename_list[100]\n",
    "print( fp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Processed Data\n",
    "#### - Example accessing MD585 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHATM2\n",
      "  - Has no processed data on S3\n",
      "CHATM3\n",
      "  - Has no processed data on S3\n",
      "CSHL2\n",
      "  - Has no processed data on S3\n",
      "MD636\n",
      "  - Has no processed data on S3\n",
      "MD639\n",
      "  - Has no processed data on S3\n",
      "MD175\n",
      "  - Has no processed data on S3\n",
      "UCSD001\n",
      "  - Has no processed data on S3\n"
     ]
    }
   ],
   "source": [
    "# Going through each brain, prints out brains that do NOT have processed data\n",
    "for stack in all_stacks:\n",
    "    # rawstack_info keys: ['mouse', 'aws_bucket', 'processed_stack']\n",
    "    processed_stack_info = (ProcessedStack()&dict(mouse=stack)).fetch( as_dict=True )[0]\n",
    "    if processed_stack_info['processed_stack']=='':\n",
    "        print(processed_stack_info['mouse'])\n",
    "        print( '  - Has no processed data on S3' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 100th slice of MD585 with the bucket appended to the front:\n",
      "\n",
      "mousebrainatlas-data/CSHL_data_processed/MD585/MD585_prep2_lossless/MD585-IHC50-2015.07.16-18.02.54_MD585_2_0149_prep2_lossless.tif\n"
     ]
    }
   ],
   "source": [
    "stack = 'MD585'\n",
    "# Load ProcessedStack table (as dict) for a particular stack\n",
    "processed_stack_info = (ProcessedStack()&dict(mouse=stack)).fetch( as_dict=True )[0]\n",
    "\n",
    "bucket =  processed_stack_info['aws_bucket']\n",
    "filename_list = processed_stack_info['processed_stack'].split('|')\n",
    "\n",
    "print( 'The 100th slice of '+stack+' with the bucket appended to the front:\\n' )\n",
    "fp = bucket + '/' + filename_list[100]\n",
    "print( fp )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Images from S3 to Local Computer\n",
    "(Relies on `bucket` and `filename_list` from previous cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "\n",
    "# `fp` includes the S3 bucket as shown belows\n",
    "def download_from_s3(local_root, fp):\n",
    "    s3_url = \"s3://\"+fp\n",
    "    local_fp = local_root+fp\n",
    "    \n",
    "    print('Downloading file to ' + local_fp)\n",
    "\n",
    "    call([\"aws\",\\\n",
    "          \"s3\",\\\n",
    "          \"cp\",\\\n",
    "          s3_url,\\\n",
    "          local_fp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD585'\n",
    "# Contains all information on downloading processed files (post-preprocessing images)\n",
    "processed_stack_info = (ProcessedStack()&dict(mouse=stack)).fetch( as_dict=True )[0]\n",
    "bucket =  processed_stack_info['aws_bucket']\n",
    "filename_list = processed_stack_info['processed_stack'].split('|')\n",
    "num_slices = len(filename_list)\n",
    "\n",
    "# Using `download_from_s3` on my desktop to download first 10 files of MD585\n",
    "#   and then display a downsampled version of it\n",
    "local_root_alex_pc = \"/mnt/c/Users/Alex/Documents/\"\n",
    "\n",
    "# Downloading valid sections 150-151\n",
    "for i in range(150,152):\n",
    "    fp = bucket+'/'+filename_list[i]\n",
    "    download_from_s3( local_root_alex_pc, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
