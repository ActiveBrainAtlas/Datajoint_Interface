{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "from minio import Minio\n",
    "import json\n",
    "import yaml\n",
    "import sys, os\n",
    "\n",
    "sys.path.append('./lib')\n",
    "from utilities import *\n",
    "from initialization_of_db import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fp to file pointers assumes to be 'setup/credFiles.yaml', otherwise pass it directly\n",
    "# Load AWS Credentials\n",
    "# `creds` needs the following fields: 'access_key', 'secret_access_key\n",
    "s3_client = get_s3_client()\n",
    "# Load Datajoint Credentials\n",
    "# `dj_creds` needs the following fields: 'user', 'passwd'\n",
    "dj_creds = get_dj_creds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting dbadmin@ucsd-demo-db.datajoint.io:3306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataJoint connection (connected) dbadmin@ucsd-demo-db.datajoint.io:3306"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to datajoint server\n",
    "dj.conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which schema you're using\n",
    "schema = dj.schema('common_atlas_v3')\n",
    "schema.spawn_missing_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays graphical reprasentation of the schema. NOT NECESSARY\n",
    "# dj.ERD(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`common_atlas_v3`.`base_image` (0 tuples)\n",
      "Proceed? [yes, No]: yes\n",
      "Tables dropped.  Restart kernel.\n",
      "`common_atlas_v3`.`base_image_yoav` (926 tuples)\n",
      "Proceed? [yes, No]: yes\n",
      "Tables dropped.  Restart kernel.\n"
     ]
    }
   ],
   "source": [
    "# BaseImage.drop()\n",
    "# BaseImageYoav.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Mouse(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    mouse : char(18)                   # Name for lab mouse, max 8 chars\n",
    "    -------\n",
    "    date_of_birth  : date              # (date) the mouse's date of birth\n",
    "    sex            : enum('M','F') # (M/F) either 'M' for male, 'F' for female\n",
    "    genotype       : enum('C57','U')     # (Lookup) indicating the genotype\n",
    "    weight         : double            # (int) weight of the mouse in grams. -1 if unknown\n",
    "    bred           : varchar(20)       # (Str) Vendor where the mouse was bred (bred in house, \\\n",
    "    #purchased by vendor)\n",
    "    \"\"\"\n",
    "    \n",
    "@schema\n",
    "class Perfusion(dj.Manual): # Everyone should be doing the same type of perfusion\n",
    "    definition = \"\"\"\n",
    "    -> Mouse                        # One injection per mouse\n",
    "    ----------\n",
    "    injection_date  : date          # (date) what day was the injection performed\n",
    "\n",
    "    post_fixation_condition_hours  : int   # (int) How long kept in fix (overnight)\n",
    "    percent_sucrose_of_fix         : int   # (int) 10 or 20 percent for CSHL stuff\n",
    "\n",
    "    date_frozen    : date     # (date) The date the brain was frozen\n",
    "    date_sectioned : date     # (date) The date the brain was sectioned\n",
    "\n",
    "    injection_type  : varchar(30)   # (Str) what kind of tracer/injection\n",
    "    perfusion_lab   : varchar(30)   # (Str) Which lab perfused the mouse? This lab also kept the mouse\n",
    "    \n",
    "    assessment=''   : varchar(1000) # (Str) optional, qualitative assessment of injection\n",
    "    \"\"\"\n",
    "    \n",
    "@schema\n",
    "class Injection(dj.Manual): # Viral injections\n",
    "    definition = \"\"\"\n",
    "    -> Mouse                        # One injection per mouse\n",
    "    injection_number : int          # iterative, how many injections have already been performed\n",
    "    -------\n",
    "    injection_date  : date          # (date) what day was the injection performed\n",
    "    injection_type  : varchar(30)   # (Str) what kind of tracer/injection (flourescent?)\n",
    "    injection_length: int           # UNSURE. Assumed: the length of time the virus was allowed to propagate\n",
    "    \n",
    "    assessment=''   : varchar(1000) # (Str) qualitative assessment of injection\n",
    "    \"\"\"\n",
    "    \n",
    "@schema\n",
    "class Histology(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Mouse                        # One Histology per injection per mouse\n",
    "    ------------\n",
    "    region         : varchar(10)    # (Str) [UNSURE]\n",
    "    thickness      : int            # (int) thickness of each slice in microns\n",
    "    orientation    : enum('sagittal','coronal','horozontal')    # (Str) horizontal, sagittal, coronal\n",
    "    counter_stain  : varchar(30)    # (Str) what stain was used on the brain (thionin or NeuroTrace)\n",
    "    lab            : varchar(20)    # (Str) Which lab did the histology\n",
    "    series         : enum('all','every other','unknown') # Every section OR alternate sections\n",
    "    \"\"\"\n",
    "# AFTER sectioning, the reporter can either be directly visualized with fuorscence or needs to be \n",
    "#  amplified with immunostaining\n",
    "# Hannah, with Axio Scanner, will manually select level of exposure to reduce saturation but make sure the \n",
    "#  the fluorescent molecules are visible\n",
    "#    - add: CSHL_did_their_own_blackbox_preprocessing : True or False\n",
    "# Assume calibration\n",
    "\n",
    "@schema \n",
    "class Stack(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> Histology            # One Histology per injection per mouse\n",
    "    ------------\n",
    "    stack_name       : varchar(10)   # (Str) unique designation for each mouse\n",
    "    num_slices       : int           # (int) total number of histology slices\n",
    "    num_valid_slices : int           # (int) total number of useable histology slices\n",
    "    channels         : int           # (int) number of channels for each slice\n",
    "    human_annotated  : boolean       # (bool) does this stack have human annotations\n",
    "\n",
    "    planar_resolution_um : double    # (double) 0.325 for AxioScanner, 0.46 from CSHL\n",
    "    section_thickness_um : double    # (double) typically 20um\n",
    "    \n",
    "    unique index (stack_name)   # Adds constraint, stack name must be unique accross brains\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Slice(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Stack\n",
    "    slice_num       : int           # (int) the unique index of the brain slice. Thickness found in Histology table\n",
    "    ---\n",
    "    slice_name      : varchar(100)  # (str) the name of the slice. Naming scheme may vary from lab to lab\n",
    "    valid           : boolean       # (bool) if false, the slice does not exist\n",
    "    raw_s3_fp       : varchar(200)  # (str)\n",
    "    processed_s3_fp : varchar(200)  # (str)\n",
    "    \"\"\"\n",
    "    def make(self, key):\n",
    "        \"\"\"\n",
    "        For every major key in the master table (Stack) the make function will run, once for every unique stack.\n",
    "        \"\"\"\n",
    "        stack_info = (Stack()&key).fetch( as_dict=True )[0]\n",
    "        stack_name = stack_info[\"stack_name\"]\n",
    "        \n",
    "        processed_files = get_processed_files( s3_client, \\\n",
    "                                              stack=stack_name, \\\n",
    "                                              prep_id=\"2\", \\\n",
    "                                              version=\"\", \\\n",
    "                                              resol=\"raw\", \\\n",
    "                                              returntype=\"list\" )\n",
    "        raw_files = get_raw_files( s3_client, \\\n",
    "                                  stack=stack_name, \\\n",
    "                                  returntype=\"list\" )\n",
    "        \n",
    "        # Load the sorted_filenames.txt into a dictionary\n",
    "        try:\n",
    "            sorted_fns,_,_ = get_sorted_filenames( s3_client, stack_name=stack_name, return_type='dictionary')\n",
    "            \n",
    "            for slice_num in sorted_fns:\n",
    "                key['slice_num'] = slice_num\n",
    "                key['slice_name'] = str( sorted_fns[slice_num] )\n",
    "                if key['slice_name'] == 'Placeholder':\n",
    "                    key['valid'] = False\n",
    "                else:\n",
    "                    key['valid'] = True\n",
    "\n",
    "                # Fill in the RAW and PROCESSED S3 filepaths\n",
    "                key['processed_s3_fp'] = ''\n",
    "                key['raw_s3_fp'] = ''\n",
    "                \n",
    "                for fp in processed_files:\n",
    "                    if key['slice_name'] in fp:\n",
    "                        key['processed_s3_fp'] = fp\n",
    "                        break\n",
    "                for fp in raw_files:\n",
    "                    if key['slice_name'] in fp:\n",
    "                        key['raw_s3_fp'] = fp\n",
    "                        break\n",
    "\n",
    "                self.insert1(key)\n",
    "                \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        print(stack_name+' finished \\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mouse.drop()\n",
    "# Slice.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill manual tables from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding MD585 to the database\n",
      "447\n",
      "\n",
      "Adding MD589 to the database\n",
      "448\n",
      "\n",
      "Adding MD590 to the database\n",
      "429\n",
      "\n",
      "Adding MD591 to the database\n",
      "456\n",
      "\n",
      "Adding MD592 to the database\n",
      "455\n",
      "\n",
      "Adding MD593 to the database\n",
      "454\n",
      "\n",
      "Adding MD594 to the database\n",
      "434\n",
      "\n",
      "Adding MD595 to the database\n",
      "445\n",
      "\n",
      "Adding MD598 to the database\n",
      "438\n",
      "\n",
      "Adding MD599 to the database\n",
      "449\n",
      "\n",
      "Adding MD602 to the database\n",
      "445\n",
      "\n",
      "Adding MD603 to the database\n",
      "438\n",
      "\n",
      "Adding CHATM2 to the database\n",
      "328\n",
      "\n",
      "Adding CHATM3 to the database\n",
      "413\n",
      "\n",
      "Adding CSHL2 to the database\n",
      "No sorted_filenames.txt exists for CSHL2\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "-1\n",
      "\n",
      "Adding MD658 to the database\n",
      "451\n",
      "\n",
      "Adding MD661 to the database\n",
      "439\n",
      "\n",
      "Adding MD662 to the database\n",
      "439\n",
      "\n",
      "Adding MD635 to the database\n",
      "445\n",
      "\n",
      "Adding MD636 to the database\n",
      "No sorted_filenames.txt exists for MD636\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "-1\n",
      "\n",
      "Adding MD639 to the database\n",
      "No sorted_filenames.txt exists for MD639\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "-1\n",
      "\n",
      "Adding MD642 to the database\n",
      "440\n",
      "\n",
      "Adding MD652 to the database\n",
      "480\n",
      "\n",
      "Adding MD653 to the database\n",
      "473\n",
      "\n",
      "Adding MD657 to the database\n",
      "450\n",
      "\n",
      "Adding MD175 to the database\n",
      "No sorted_filenames.txt exists for MD175\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "-1\n",
      "\n",
      "Adding UCSD001 to the database\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "for brain_name in brain_names_list:\n",
    "\n",
    "    print(\"\\nAdding \"+brain_name+' to the database')\n",
    "    \n",
    "    # Fill in MOUSE info for UCSD\n",
    "    if brain_name == 'UCSD001':\n",
    "        Mouse.insert1(dict(mouse=brain_name,\n",
    "                   date_of_birth='2020-01-01',\n",
    "                   sex='M',\n",
    "                   genotype='C57',\n",
    "                   weight=-1,\n",
    "                   bred='Unknown')\n",
    "                 ,skip_duplicates=True)\n",
    "    else: # Fill in MOUSE info non-UCSD mice\n",
    "        Mouse.insert1(dict(mouse=brain_name,\n",
    "                       date_of_birth='2017-12-05',\n",
    "                       sex='M',\n",
    "                       genotype='C57',\n",
    "                       weight=-1,\n",
    "                       bred='Unknown')\n",
    "                     ,skip_duplicates=True)\n",
    "        \n",
    "    # Fill in HISTOLOGY info\n",
    "    Histology.insert1((brain_name,\n",
    "                   'Unknown', # region\n",
    "                   '20', # thickness\n",
    "                   brain_names_dic[brain_name][3],  # orientation\n",
    "                   brain_names_dic[brain_name][0],  # counter_stain\n",
    "                   brain_names_dic[brain_name][1],  # lab\n",
    "                   'unknown') # series  \n",
    "                 ,skip_duplicates=True)\n",
    "    \n",
    "    # Try to load STACK_sorted_filenames.txt from AWS S3, on failure the default values are filled\n",
    "    try:\n",
    "        _, total_slices, valid_slices = get_sorted_filenames( s3_client, \\\n",
    "                                                             stack_name=brain_name, \\\n",
    "                                                             return_type=\"string\" )\n",
    "    except Exception as e:\n",
    "        total_slices   = -1\n",
    "        valid_slices   = -1\n",
    "        print('No sorted_filenames.txt exists for '+brain_name)\n",
    "        print(e)\n",
    "\n",
    "    # Fill in STACK info for UCSD\n",
    "    if brain_name == 'UCSD001':\n",
    "        Stack.insert1(dict(mouse=brain_name,\n",
    "                                stack_name=brain_name,\n",
    "                                num_slices       = total_slices,\n",
    "                                num_valid_slices = valid_slices,\n",
    "                                channels         = brain_names_dic[brain_name][0].count('/') + 1,\n",
    "                                human_annotated  = brain_names_dic[brain_name][2],\n",
    "                                planar_resolution_um = 0.325,\n",
    "                                section_thickness_um = 20)\n",
    "                     ,skip_duplicates=True)\n",
    "    else:# Fill in STACK info for non-UCSD brains\n",
    "        Stack.insert1(dict(mouse=brain_name,\n",
    "                                stack_name=brain_name,\n",
    "                                num_slices       = total_slices,\n",
    "                                num_valid_slices = valid_slices,\n",
    "                                channels         = brain_names_dic[brain_name][0].count('/') + 1,\n",
    "                                human_annotated  = brain_names_dic[brain_name][2],\n",
    "                                planar_resolution_um = 0.46,\n",
    "                                section_thickness_um = 20)\n",
    "                     ,skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHATM2 finished \n",
      "\n",
      "CHATM3 finished \n",
      "\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "CSHL2 finished \n",
      "\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "MD175 finished \n",
      "\n",
      "MD585 finished \n",
      "\n",
      "MD589 finished \n",
      "\n",
      "MD590 finished \n",
      "\n",
      "MD591 finished \n",
      "\n",
      "MD592 finished \n",
      "\n",
      "MD593 finished \n",
      "\n",
      "MD594 finished \n",
      "\n",
      "MD595 finished \n",
      "\n",
      "MD598 finished \n",
      "\n",
      "MD599 finished \n",
      "\n",
      "MD602 finished \n",
      "\n",
      "MD603 finished \n",
      "\n",
      "MD635 finished \n",
      "\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "MD636 finished \n",
      "\n",
      "NoSuchKey: message: The specified key does not exist.\n",
      "MD639 finished \n",
      "\n",
      "MD642 finished \n",
      "\n",
      "MD652 finished \n",
      "\n",
      "MD653 finished \n",
      "\n",
      "MD657 finished \n",
      "\n",
      "MD658 finished \n",
      "\n",
      "MD661 finished \n",
      "\n",
      "MD662 finished \n",
      "\n",
      "UCSD001 finished \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Slice.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
